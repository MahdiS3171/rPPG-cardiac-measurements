{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "8otC2JYjZOf7"
      },
      "id": "8otC2JYjZOf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PvxPwylmZg0X",
        "outputId": "276edf36-d760-45df-b7db-7e675ea6822d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PvxPwylmZg0X",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "683dc8a5",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "683dc8a5",
        "outputId": "a94bd9cf-8e5a-4231-be72-a4a3cbe7143e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/rPPG/input_1.mp4\"     # your input video\n",
        "save_path = \"/content/drive/MyDrive/rPPG/rppg_raw_landmarks.npz\"\n",
        "max_frames = None                  # e.g. 1000 to limit, or None for all\n",
        "show_debug = True                  # show frame with circles\n",
        "min_face_eye_dist = 60             # skip very small faces (in pixels)\n",
        "roi_radius_factor = 0.1           # ROI radius = this * inter-eye distance"
      ],
      "metadata": {
        "id": "j80IdIW8aEXM"
      },
      "id": "j80IdIW8aEXM",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lm_to_px(lm, w, h):\n",
        "    \"\"\"Convert one normalized landmark to integer pixel coords.\"\"\"\n",
        "    x = int(lm.x * w)\n",
        "    y = int(lm.y * h)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def get_circular_roi_mean_rgb(frame_rgb, cx, cy, radius):\n",
        "    \"\"\"Return mean [R,G,B] in a circular ROI centered at (cx,cy).\"\"\"\n",
        "    h, w, _ = frame_rgb.shape\n",
        "    # bounding box of the circle\n",
        "    x1 = max(cx - radius, 0)\n",
        "    x2 = min(cx + radius, w - 1)\n",
        "    y1 = max(cy - radius, 0)\n",
        "    y2 = min(cy + radius, h - 1)\n",
        "\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return None\n",
        "\n",
        "    # build mask for the circle\n",
        "    yy, xx = np.ogrid[y1:y2, x1:x2]\n",
        "    dist_sq = (xx - cx) ** 2 + (yy - cy) ** 2\n",
        "    mask = dist_sq <= radius ** 2\n",
        "\n",
        "    roi_pixels = frame_rgb[y1:y2, x1:x2, :][mask]\n",
        "    if roi_pixels.size == 0:\n",
        "        return None\n",
        "\n",
        "    return roi_pixels.mean(axis=0)  # [R,G,B]\n",
        "\n",
        "def combine_rois_rgb(forehead_list, left_cheek_list, right_cheek_list,\n",
        "                     normalize_per_roi=True):\n",
        "    \"\"\"\n",
        "    Combine multiple ROI RGB signals from forehead, left cheek,\n",
        "    and right cheek into a single face RGB signal.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    forehead_list : list of arrays, each (N,3)\n",
        "    left_cheek_list : list of arrays, each (N,3)\n",
        "    right_cheek_list : list of arrays, each (N,3)\n",
        "    normalize_per_roi : bool\n",
        "        Whether to normalize each ROI individually.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rgb_mean : array (N,3)\n",
        "        The combined face RGB signal.\n",
        "    \"\"\"\n",
        "    # Merge all ROI lists into one flat list\n",
        "    all_rois = forehead_list + left_cheek_list + right_cheek_list\n",
        "\n",
        "    rgb_all = []\n",
        "\n",
        "    for roi in all_rois:\n",
        "        rgb = roi.astype(np.float64)\n",
        "\n",
        "        if normalize_per_roi:\n",
        "            mu = rgb.mean(axis=0)\n",
        "            sigma = rgb.std(axis=0) + 1e-8\n",
        "            rgb = (rgb - mu) / sigma\n",
        "\n",
        "        rgb_all.append(rgb)\n",
        "\n",
        "    # Stack into (num_rois, N, 3)\n",
        "    rgb_all = np.stack(rgb_all, axis=0)\n",
        "\n",
        "    # Average across ROIs\n",
        "    rgb_mean = rgb_all.mean(axis=0)  # (N,3)\n",
        "\n",
        "    return rgb_mean"
      ],
      "metadata": {
        "id": "wLZBYYlwaLHJ"
      },
      "id": "wLZBYYlwaLHJ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"Video FPS:\", fps)"
      ],
      "metadata": {
        "id": "rIr6vK3-a1w-",
        "outputId": "b9c5c7ae-1dca-4015-fe98-94023342ad01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rIr6vK3-a1w-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video FPS: 30.00285032591299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=False,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=False,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5,\n",
        ")"
      ],
      "metadata": {
        "id": "fra-t3hcbNIC"
      },
      "id": "fra-t3hcbNIC",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# landmark indices we use\n",
        "FOREHEAD_IDX = [10,109,108,107,9,336,337,338]\n",
        "LEFT_CHEEK_IDX = [118, 119, 100, 126, 209, 49, 129, 203, 205, 50]\n",
        "RIGHT_CHEEK_IDX = [347, 348, 329, 355, 429, 279, 358, 423, 425, 280]\n",
        "LEFT_EYE_OUTER = 33\n",
        "RIGHT_EYE_OUTER = 263\n",
        "\n",
        "timestamps = []\n",
        "forehead_rgb = []\n",
        "left_cheek_rgb = []\n",
        "right_cheek_rgb = []\n",
        "combined_rgb = []\n",
        "\n",
        "frame_idx = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame_bgr = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if max_frames is not None and frame_idx >= max_frames:\n",
        "        break\n",
        "\n",
        "    frame_idx += 1\n",
        "    h, w, _ = frame_bgr.shape\n",
        "\n",
        "    # BGR -> RGB for MediaPipe\n",
        "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(frame_rgb)\n",
        "\n",
        "    if not results.multi_face_landmarks:\n",
        "        continue\n",
        "\n",
        "    face_lms = results.multi_face_landmarks[0].landmark\n",
        "\n",
        "    # --- compute scale: inter-eye distance ---\n",
        "    lx, ly = lm_to_px(face_lms[LEFT_EYE_OUTER], w, h)\n",
        "    rx, ry = lm_to_px(face_lms[RIGHT_EYE_OUTER], w, h)\n",
        "    eye_dist = np.hypot(rx - lx, ry - ly)\n",
        "\n",
        "    if eye_dist < min_face_eye_dist:\n",
        "        # face too small for reliable rPPG\n",
        "        continue\n",
        "\n",
        "    radius = int(roi_radius_factor * eye_dist)\n",
        "    if radius < 3:\n",
        "        continue\n",
        "\n",
        "    for idxf in FOREHEAD_IDX:\n",
        "        # --- ROI centers from landmarks ---\n",
        "      fh_cx, fh_cy = lm_to_px(face_lms[idxf], w, h)\n",
        "\n",
        "      # --- compute mean RGB in circular ROIs ---\n",
        "      fh_mean = get_circular_roi_mean_rgb(frame_rgb, fh_cx, fh_cy, radius)\n",
        "\n",
        "      if fh_mean is None:\n",
        "          continue\n",
        "\n",
        "      forehead_rgb.append(fh_mean)\n",
        "\n",
        "    for idxl in LEFT_CHEEK_IDX:\n",
        "        # --- ROI centers from landmarks ---\n",
        "      lc_cx, lc_cy = lm_to_px(face_lms[idxl], w, h)\n",
        "\n",
        "      # --- compute mean RGB in circular ROIs ---\n",
        "      lc_mean = get_circular_roi_mean_rgb(frame_rgb, lc_cx, lc_cy, radius)\n",
        "\n",
        "      if lc_mean is None:\n",
        "          continue\n",
        "\n",
        "      left_cheek_rgb.append(lc_mean)\n",
        "\n",
        "    for idxr in LEFT_CHEEK_IDX:\n",
        "        # --- ROI centers from landmarks ---\n",
        "      rc_cx, rc_cy = lm_to_px(face_lms[idxr], w, h)\n",
        "\n",
        "      # --- compute mean RGB in circular ROIs ---\n",
        "      rc_mean = get_circular_roi_mean_rgb(frame_rgb, rc_cx, rc_cy, radius)\n",
        "\n",
        "      if rc_mean is None:\n",
        "          continue\n",
        "\n",
        "      right_cheek_rgb.append(rc_mean)\n",
        "\n",
        "    combined_rgb = combine_rois_rgb(forehead_rgb, left_cheek_rgb, right_cheek_rgb)\n",
        "\n",
        "    t = frame_idx / fps if fps > 0 else frame_idx\n",
        "    timestamps.append(t)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "face_mesh.close()\n",
        "\n",
        "# --- save data ---\n",
        "timestamps = np.array(timestamps)\n",
        "forehead_rgb = np.vstack(forehead_rgb)\n",
        "left_cheek_rgb = np.vstack(left_cheek_rgb)\n",
        "right_cheek_rgb = np.vstack(right_cheek_rgb)\n",
        "\n",
        "print(\"Collected frames:\", len(timestamps))\n",
        "print(\"Saving to:\", save_path)\n",
        "\n",
        "np.savez(\n",
        "    save_path,\n",
        "    timestamps=timestamps,\n",
        "    fps=fps,\n",
        "    forehead=forehead_rgb,\n",
        "    left_cheek=left_cheek_rgb,\n",
        "    right_cheek=right_cheek_rgb,\n",
        ")"
      ],
      "metadata": {
        "id": "eLsrXCtkbQda"
      },
      "id": "eLsrXCtkbQda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"input.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    green = frame[:, :, 1]\n",
        "\n",
        "    # Recreate an image that only has green values\n",
        "    green_img = np.zeros_like(frame)\n",
        "    green_img[:, :, 1] = green  # Only G channel active\n",
        "\n",
        "    cv2.imshow(\"Green\", green_img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "DQLenDW3kecf"
      },
      "id": "DQLenDW3kecf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}